{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises - Pre-Defined Functions\n",
    "\n",
    "Here are the exercises to ensure our understanding related to Pre-Defined Functions.\n",
    "* We will use **users** table as well as other tables we got as part of retail database.\n",
    "* Information will be provided with each exercise.\n",
    "Let us start spark context for this Notebook so that we can execute the code provided. You can sign up for our [10 node state of the art cluster/labs](https://labs.itversity.com/plans) to learn Spark SQL using our unique integrated LMS.\n",
    "val username = System.getProperty(\"user.name\")\n",
    "import org.apache.spark.sql.SparkSession\n",
    "\n",
    "val username = System.getProperty(\"user.name\")\n",
    "val spark = SparkSession.\n",
    "    builder.\n",
    "    config(\"spark.ui.port\", \"0\").\n",
    "    config(\"spark.sql.warehouse.dir\", s\"/user/${username}/warehouse\").\n",
    "    enableHiveSupport.\n",
    "    appName(s\"${username} | Spark SQL - Predefined Functions\").\n",
    "    master(\"yarn\").\n",
    "    getOrCreate\n",
    "If you are going to use CLIs, you can use Spark SQL using one of the 3 approaches.\n",
    "\n",
    "\n",
    "```\n",
    "%%sql\n",
    "\n",
    "USE itversity_retail\n",
    "%%sql\n",
    "\n",
    "DROP TABLE IF EXISTS users\n",
    "%%sql\n",
    "\n",
    "CREATE TABLE users(\n",
    "    user_id INT,\n",
    "    user_first_name VARCHAR(30),\n",
    "    user_last_name VARCHAR(30),\n",
    "    user_email_id VARCHAR(50),\n",
    "    user_gender VARCHAR(1),\n",
    "    user_unique_id VARCHAR(15),\n",
    "    user_phone_no VARCHAR(20),\n",
    "    user_dob DATE,\n",
    "    created_ts TIMESTAMP\n",
    ")\n",
    "%%sql\n",
    "\n",
    "INSERT INTO users\n",
    "VALUES\n",
    "    (1, 'Giuseppe', 'Bode', 'gbode0@imgur.com', 'M', '88833-8759', \n",
    "     '+86 (764) 443-1967', '1973-05-31', '2018-04-15 12:13:38'),\n",
    "    (2, 'Lexy', 'Gisbey', 'lgisbey1@mail.ru', 'F', '262501-029', \n",
    "     '+86 (751) 160-3742', '2003-05-31', '2020-12-29 06:44:09'),\n",
    "    (3, 'Karel', 'Claringbold', 'kclaringbold2@yale.edu', 'F', '391-33-2823', \n",
    "     '+62 (445) 471-2682', '1985-11-28', '2018-11-19 00:04:08'),\n",
    "    (4, 'Marv', 'Tanswill', 'mtanswill3@dedecms.com', 'F', '1195413-80', \n",
    "     '+62 (497) 736-6802', '1998-05-24', '2018-11-19 16:29:43'),\n",
    "    (5, 'Gertie', 'Espinoza', 'gespinoza4@nationalgeographic.com', 'M', '471-24-6869', \n",
    "     '+249 (687) 506-2960', '1997-10-30', '2020-01-25 21:31:10'),\n",
    "    (6, 'Saleem', 'Danneil', 'sdanneil5@guardian.co.uk', 'F', '192374-933', \n",
    "     '+63 (810) 321-0331', '1992-03-08', '2020-11-07 19:01:14'),\n",
    "    (7, 'Rickert', 'O''Shiels', 'roshiels6@wikispaces.com', 'M', '749-27-47-52', \n",
    "     '+86 (184) 759-3933', '1972-11-01', '2018-03-20 10:53:24'),\n",
    "    (8, 'Cybil', 'Lissimore', 'clissimore7@pinterest.com', 'M', '461-75-4198', \n",
    "     '+54 (613) 939-6976', '1978-03-03', '2019-12-09 14:08:30'),\n",
    "    (9, 'Melita', 'Rimington', 'mrimington8@mozilla.org', 'F', '892-36-676-2', \n",
    "     '+48 (322) 829-8638', '1995-12-15', '2018-04-03 04:21:33'),\n",
    "    (10, 'Benetta', 'Nana', 'bnana9@google.com', 'M', '197-54-1646', \n",
    "     '+420 (934) 611-0020', '1971-12-07', '2018-10-17 21:02:51'),\n",
    "    (11, 'Gregorius', 'Gullane', 'ggullanea@prnewswire.com', 'F', '232-55-52-58', \n",
    "     '+62 (780) 859-1578', '1973-09-18', '2020-01-14 23:38:53'),\n",
    "    (12, 'Una', 'Glayzer', 'uglayzerb@pinterest.com', 'M', '898-84-336-6', \n",
    "     '+380 (840) 437-3981', '1983-05-26', '2019-09-17 03:24:21'),\n",
    "    (13, 'Jamie', 'Vosper', 'jvosperc@umich.edu', 'M', '247-95-68-44', \n",
    "     '+81 (205) 723-1942', '1972-03-18', '2020-07-23 16:39:33'),\n",
    "    (14, 'Calley', 'Tilson', 'ctilsond@issuu.com', 'F', '415-48-894-3', \n",
    "     '+229 (698) 777-4904', '1987-06-12', '2020-06-05 12:10:50'),\n",
    "    (15, 'Peadar', 'Gregorowicz', 'pgregorowicze@omniture.com', 'M', '403-39-5-869', \n",
    "     '+7 (267) 853-3262', '1996-09-21', '2018-05-29 23:51:31'),\n",
    "    (16, 'Jeanie', 'Webling', 'jweblingf@booking.com', 'F', '399-83-05-03', \n",
    "     '+351 (684) 413-0550', '1994-12-27', '2018-02-09 01:31:11'),\n",
    "    (17, 'Yankee', 'Jelf', 'yjelfg@wufoo.com', 'F', '607-99-0411', \n",
    "     '+1 (864) 112-7432', '1988-11-13', '2019-09-16 16:09:12'),\n",
    "    (18, 'Blair', 'Aumerle', 'baumerleh@toplist.cz', 'F', '430-01-578-5', \n",
    "     '+7 (393) 232-1860', '1979-11-09', '2018-10-28 19:25:35'),\n",
    "    (19, 'Pavlov', 'Steljes', 'psteljesi@macromedia.com', 'F', '571-09-6181', \n",
    "     '+598 (877) 881-3236', '1991-06-24', '2020-09-18 05:34:31'),\n",
    "    (20, 'Darn', 'Hadeke', 'dhadekej@last.fm', 'M', '478-32-02-87', \n",
    "     '+370 (347) 110-4270', '1984-09-04', '2018-02-10 12:56:00'),\n",
    "    (21, 'Wendell', 'Spanton', 'wspantonk@de.vu', 'F', null, \n",
    "     '+84 (301) 762-1316', '1973-07-24', '2018-01-30 01:20:11'),\n",
    "    (22, 'Carlo', 'Yearby', 'cyearbyl@comcast.net', 'F', null, \n",
    "     '+55 (288) 623-4067', '1974-11-11', '2018-06-24 03:18:40'),\n",
    "    (23, 'Sheila', 'Evitts', 'sevittsm@webmd.com', null, '830-40-5287',\n",
    "     null, '1977-03-01', '2020-07-20 09:59:41'),\n",
    "    (24, 'Sianna', 'Lowdham', 'slowdhamn@stanford.edu', null, '778-0845', \n",
    "     null, '1985-12-23', '2018-06-29 02:42:49'),\n",
    "    (25, 'Phylys', 'Aslie', 'paslieo@qq.com', 'M', '368-44-4478', \n",
    "     '+86 (765) 152-8654', '1984-03-22', '2019-10-01 01:34:28')\n",
    "%%sql\n",
    "\n",
    "SELECT * FROM users LIMIT 10\n",
    "\n",
    "### Exercise 1\n",
    "Get all the number of users created per year.\n",
    "* Use **users** table for this exercise.\n",
    "* Output should contain 4 digit year and count.\n",
    "* Use date specific functions to get the year using created_ts.\n",
    "* Make sure you define aliases to the columns as **created_year** and **user_count** respectively.\n",
    "* Data should be sorted in ascending order by **created_year**.\n",
    "* When you run the query using Jupyter environment, it might have decimals for integers. Hence you can display results even with decimal points.\n",
    "* Here is the sample output.\n",
    "\n",
    "|created_year|user_count|\n",
    "|----|--|\n",
    "|2018|13|\n",
    "|2019|4|\n",
    "|2020|8|\n",
    "\n",
    "\n",
    "### Exercise 2\n",
    "\n",
    "Get the day name of the birth days for all the users born in the month of June.\n",
    "* Use **users** table for this exercise.\n",
    "* Output should contain user_id, user_dob, user_email_id and user_day_of_birth.\n",
    "* Use date specific functions to get the month using user_dob.\n",
    "* **user_day_of_birth** should be full day with first character in upper case such as **Tuesday**\n",
    "* Data should be sorted by day with in the month of May.\n",
    "\n",
    "|user_id|user_dob|user_email_id|user_day_of_birth|\n",
    "|-|----------|----------------------|------|\n",
    "|4|1998-05-24|mtanswill3@dedecms.com|Sunday|\n",
    "|12|1983-05-26|uglayzerb@pinterest.com|Thursday|\n",
    "|1|1973-05-31|gbode0@imgur.com|Thursday|\n",
    "|2|2003-05-31|lgisbey1@mail.ru|Saturday|\n",
    "### Exercise 3\n",
    "\n",
    "Get the names and email ids of users added in year 2019.\n",
    "\n",
    "* Use **users** table for this exercise.\n",
    "* Output should contain user_id, user_name, user_email_id, created_ts, created_year.\n",
    "* Use date specific functions to get the year using created_ts.\n",
    "* **user_name** is a derived column by concatenating user_first_name and user_last_name with space in between.\n",
    "* **user_name** should have values in upper case.\n",
    "* Data should be sorted in ascending order by user_name\n",
    "\n",
    "|user_id|user_name|user_email_id|created_ts|created_year|\n",
    "|-|---------|------|------|------|\n",
    "|8|CYBIL LISSIMORE|clissimore7@pinterest.com|2019-12-09 14:08:30|2019.0|\n",
    "|25|PHYLYS ASLIE|paslieo@qq.com|2019-10-01 01:34:28|2019.0|\n",
    "|12|UNA GLAYZER|uglayzerb@pinterest.com|2019-09-17 03:24:21|2019.0|\n",
    "|17|YANKEE JELF|yjelfg@wufoo.com|2019-09-16 16:09:12|2019.0|\n",
    "\n",
    "\n",
    "### Exercise 4\n",
    "\n",
    "Get the number of users by gender.\n",
    "\n",
    "* Use **users** table for this exercise.\n",
    "* Output should contain gender and user_count.\n",
    "* For males the output should display **Male** and for females the output should display **Female**.\n",
    "* If gender is not specified, then it should display **Not Specified**.\n",
    "* Data should be sorted in descending order by user_count.\n",
    "\n",
    "|user_gender|user_count|\n",
    "|----|--|\n",
    "|Female|13|\n",
    "|Male|10|\n",
    "|Not Specified|2|\n",
    "\n",
    "\n",
    "### Exercise 5\n",
    "\n",
    "Get last 4 digits of unique ids.\n",
    "\n",
    "* Use **users** table for this exercise.\n",
    "* Output should contain user_id, user_unique_id and user_unique_id_last4\n",
    "* Unique ids are either null or not null.\n",
    "* Unique ids contain numbers and hyphens and are of different length.\n",
    "* We need to get last 4 digits discarding hyphens only when the number of digits are at least 9.\n",
    "* If unique id is null, then you should dispaly **Not Specified**.\n",
    "* After discarding hyphens, if unique id have less than 9 digits then you should display **Invalid Unique Id**.\n",
    "* Data should be sorted by user_id. You might see **None** or **null** for those user ids where there is no unique id for **user_unique_id**\n",
    "\n",
    "|user_id|user_unique_id|user_unique_id_last4|\n",
    "|-|----|----|\n",
    "|1|88833-8759|8759|\n",
    "|2|262501-029|1029|\n",
    "|3|391-33-2823|2823|\n",
    "|4|1195413-80|1380|\n",
    "|5|471-24-6869|6869|\n",
    "|6|192374-933|4933|\n",
    "|7|749-27-47-52|4752|\n",
    "|8|461-75-4198|4198|\n",
    "|9|892-36-676-2|6762|\n",
    "|10|197-54-1646|1646|\n",
    "|11|232-55-52-58|5258|\n",
    "|12|898-84-336-6|3366|\n",
    "|13|247-95-68-44|6844|\n",
    "|14|415-48-894-3|8943|\n",
    "|15|403-39-5-869|5869|\n",
    "|16|399-83-05-03|0503|\n",
    "|17|607-99-0411|0411|\n",
    "|18|430-01-578-5|5785|\n",
    "|19|571-09-6181|6181|\n",
    "|20|478-32-02-87|0287|\n",
    "|21||Not Specified|\n",
    "|22||Not Specified|\n",
    "|23|830-40-5287|5287|\n",
    "|24|778-0845|Invalid Unique Id|\n",
    "|25|368-44-4478|4478|\n",
    "### Exercise 6\n",
    "\n",
    "Get the count of users based up on country code.\n",
    "\n",
    "* Use users table for this exercise.\n",
    "* Output should contain country code and count.\n",
    "* There should be no `+` in the country code. It should only contain digits.\n",
    "* Data should be sorted as numbers by country code.\n",
    "* We should discard user_phone_no with null values.\n",
    "* Here is the desired output:\n",
    "\n",
    "|country_code|user_count|\n",
    "|-|-|\n",
    "|1|1|\n",
    "|7|2|\n",
    "|48|1|\n",
    "|54|1|\n",
    "|55|1|\n",
    "|62|3|\n",
    "|63|1|\n",
    "|81|1|\n",
    "|84|1|\n",
    "|86|4|\n",
    "|229|1|\n",
    "|249|1|\n",
    "|351|1|\n",
    "|370|1|\n",
    "|380|1|\n",
    "|420|1|\n",
    "|598|1|\n",
    "### Exercise 7\n",
    "\n",
    "Let us validate if we have invalid **order_item_subtotal** as part of **order_items** table.\n",
    "\n",
    "* **order_items** table have 6 fields.\n",
    "  * order_item_id\n",
    "  * order_item_order_id\n",
    "  * order_item_product_id\n",
    "  * order_item_quantity\n",
    "  * order_item_subtotal\n",
    "  * order_item_product_price\n",
    "* **order_item_subtotal** is nothing but product of **order_item_quantity** and **order_item_product_price**. It means order_item_subtotal is compute by multiplying order_item_quantity and order_item_product_price for each item.\n",
    "* You need to get the count of order_items where **order_item_subtotal** is not equal to the product of **order_item_quantity** and **order_item_product_price**.\n",
    "* There can be issues related to rounding off. Make sure it is taken care using appropriate function.\n",
    "* Output should be 0 as there are no such records.\n",
    "\n",
    "|count|\n",
    "|-|\n",
    "|0|\n",
    "### Exercise 8\n",
    "\n",
    "Get number of orders placed on weekdays and weekends in the month of January 2014.\n",
    "\n",
    "* **orders** have 4 fields\n",
    "  * order_id\n",
    "  * order_date\n",
    "  * order_customer_id\n",
    "  * order_status\n",
    "* Use order date to determine the day on which orders are placed.\n",
    "* Output should contain 2 columns - day_type and order_count.\n",
    "* **day_type** should have 2 values **Week days** and **Weekend days**.\n",
    "* Here is the desired output.\n",
    "\n",
    "|day_type|order_count|\n",
    "|-|-|\n",
    "|Weekend days|1505|\n",
    "|Week days|4403|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises - Windowing Functions\n",
    "\n",
    "Let us take care of the exercises related to windowing or analytics functions. We will be using HR database for the same.\n",
    "\n",
    "* Get all the employees who is making more than average salary with in each department.\n",
    "* Get cumulative salary for one of the department along with department name.\n",
    "* Get top 3 paid employees with in each department by salary (use dense_rank)\n",
    "* Get top 3 products sold in the month of 2014 January by revenue.\n",
    "* Get top 3 products in each category sold in the month of 2014 January by revenue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Get all the employees who is making more than average salary with in each department.\n",
    "\n",
    "* Use HR database employees and department tables for this problem.\n",
    "* Compute average salary expense for each department and get those employee details who are making more salary than average salary.\n",
    "* Make sure average salary expense per department is rounded off to 2 decimals.\n",
    "* Output should contain employee_id, department_name, salary and avg_salary_expense (derived field).\n",
    "* Data should be sorted in ascending order by department_id and descending order by salary.\n",
    "\n",
    "|employee_id|department_name|salary|avg_salary_expense|\n",
    "|---|---|---|---|\n",
    "|201|Marketing|13000.00|9500.00|\n",
    "|114|Purchasing|11000.00|4150.00|\n",
    "|121|Shipping|8200.00|3475.56|\n",
    "|120|Shipping|8000.00|3475.56|\n",
    "|122|Shipping|7900.00|3475.56|\n",
    "|123|Shipping|6500.00|3475.56|\n",
    "|124|Shipping|5800.00|3475.56|\n",
    "|184|Shipping|4200.00|3475.56|\n",
    "|185|Shipping|4100.00|3475.56|\n",
    "|192|Shipping|4000.00|3475.56|\n",
    "|193|Shipping|3900.00|3475.56|\n",
    "|188|Shipping|3800.00|3475.56|\n",
    "|137|Shipping|3600.00|3475.56|\n",
    "|189|Shipping|3600.00|3475.56|\n",
    "|141|Shipping|3500.00|3475.56|\n",
    "|103|IT|9000.00|5760.00|\n",
    "|104|IT|6000.00|5760.00|\n",
    "|145|Sales|14000.00|8955.88|\n",
    "|146|Sales|13500.00|8955.88|\n",
    "|147|Sales|12000.00|8955.88|\n",
    "|168|Sales|11500.00|8955.88|\n",
    "|148|Sales|11000.00|8955.88|\n",
    "|174|Sales|11000.00|8955.88|\n",
    "|149|Sales|10500.00|8955.88|\n",
    "|162|Sales|10500.00|8955.88|\n",
    "|156|Sales|10000.00|8955.88|\n",
    "|150|Sales|10000.00|8955.88|\n",
    "|169|Sales|10000.00|8955.88|\n",
    "|170|Sales|9600.00|8955.88|\n",
    "|163|Sales|9500.00|8955.88|\n",
    "|151|Sales|9500.00|8955.88|\n",
    "|157|Sales|9500.00|8955.88|\n",
    "|158|Sales|9000.00|8955.88|\n",
    "|152|Sales|9000.00|8955.88|\n",
    "|100|Executive|24000.00|19333.33|\n",
    "|108|Finance|12000.00|8600.00|\n",
    "|109|Finance|9000.00|8600.00|\n",
    "|205|Accounting|12000.00|10150.00|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Get cumulative salary with in each department for Finance and IT department along with department name.\n",
    "\n",
    "* Use HR database employees and department tables for this problem.\n",
    "* Compute cumulative salary expense for **Finance** as well as **IT** departments with in respective departments.\n",
    "* Make sure cumulative salary expense per department is rounded off to 2 decimals.\n",
    "* Output should contain employee_id, department_name, salary and cum_salary_expense (derived field).\n",
    "* Data should be sorted in ascending order by department_name and then salary.\n",
    "\n",
    "|employee_id|department_name|salary|cum_salary_expense|\n",
    "|---|---|---|---|\n",
    "|113|Finance|6900.00|6900.00|\n",
    "|111|Finance|7700.00|14600.00|\n",
    "|112|Finance|7800.00|22400.00|\n",
    "|110|Finance|8200.00|30600.00|\n",
    "|109|Finance|9000.00|39600.00|\n",
    "|108|Finance|12000.00|51600.00|\n",
    "|107|IT|4200.00|4200.00|\n",
    "|106|IT|4800.00|9000.00|\n",
    "|105|IT|4800.00|13800.00|\n",
    "|104|IT|6000.00|19800.00|\n",
    "|103|IT|9000.00|28800.00|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Get top 3 paid employees with in each department by salary (use dense_rank)\n",
    "\n",
    "* Use HR database employees and department tables for this problem.\n",
    "* Highest paid employee should be ranked first.\n",
    "* Output should contain employee_id, department_id, department_name, salary and employee_rank (derived field).\n",
    "* Data should be sorted in ascending order by department_id in ascending order and then salary in descending order.\n",
    "\n",
    "|employee_id|department_id|department_name|salary|employee_rank|\n",
    "|---|---|---|---|---|\n",
    "|200|10|Administration|4400.00|1|\n",
    "|201|20|Marketing|13000.00|1|\n",
    "|202|20|Marketing|6000.00|2|\n",
    "|114|30|Purchasing|11000.00|1|\n",
    "|115|30|Purchasing|3100.00|2|\n",
    "|116|30|Purchasing|2900.00|3|\n",
    "|203|40|Human Resources|6500.00|1|\n",
    "|121|50|Shipping|8200.00|1|\n",
    "|120|50|Shipping|8000.00|2|\n",
    "|122|50|Shipping|7900.00|3|\n",
    "|103|60|IT|9000.00|1|\n",
    "|104|60|IT|6000.00|2|\n",
    "|105|60|IT|4800.00|3|\n",
    "|106|60|IT|4800.00|3|\n",
    "|204|70|Public Relations|10000.00|1|\n",
    "|145|80|Sales|14000.00|1|\n",
    "|146|80|Sales|13500.00|2|\n",
    "|147|80|Sales|12000.00|3|\n",
    "|100|90|Executive|24000.00|1|\n",
    "|101|90|Executive|17000.00|2|\n",
    "|102|90|Executive|17000.00|2|\n",
    "|108|100|Finance|12000.00|1|\n",
    "|109|100|Finance|9000.00|2|\n",
    "|110|100|Finance|8200.00|3|\n",
    "|205|110|Accounting|12000.00|1|\n",
    "|206|110|Accounting|8300.00|2|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "Get top 3 products sold in the month of 2014 January by revenue.\n",
    "\n",
    "* Use retail database tables such as orders, order_items and products.\n",
    "* Highest revenue generating product should come at top.\n",
    "* Output should contain product_id, product_name, revenue, product_rank. **revenue** and **product_rank** are derived fields.\n",
    "* Data should be sorted in descending order by revenue.\n",
    "\n",
    "|product_id|product_name|revenue|product_rank|\n",
    "|---|---|---|---|\n",
    "|1004|Field & Stream Sportsman 16 Gun Fire Safe|250787.46|1|\n",
    "|365|Perfect Fitness Perfect Rip Deck|151474.75|2|\n",
    "|957|Diamondback Women's Serene Classic Comfort Bi|148190.12|3|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "Get top 3 products sold in the month of 2014 January under selected categories by revenue. The categories are **Cardio Equipment** and **Strength Training**.\n",
    "\n",
    "* Use retail database tables such as orders, order_items, products as well as categories.\n",
    "* Highest revenue generating product should come at top.\n",
    "* Output should contain category_id, category_name, product_id, product_name, revenue, product_rank. revenue and product_rank are derived fields.\n",
    "* Data should be sorted in ascending order by category_id and descending order by revenue.\n",
    "\n",
    "|category_id|category_name|product_id|product_name|revenue|product_rank|\n",
    "|---|---|---|---|---|---|\n",
    "|9|Cardio Equipment|191|Nike Men's Free 5.0+ Running Shoe|132286.77|1|\n",
    "|9|Cardio Equipment|172|Nike Women's Tempo Shorts|870.00|2|\n",
    "|10|Strength Training|208|SOLE E35 Elliptical|1999.99|1|\n",
    "|10|Strength Training|203|GoPro HERO3+ Black Edition Camera|1199.97|2|\n",
    "|10|Strength Training|216|Yakima DoubleDown Ace Hitch Mount 4-Bike Rack|189.00|3|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fa6fc890c19d0518efc3ca8fefe1ab7c2a921b84ac247755bf14d3f8c1bb1ece"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
